@article{ABUEBAYYEH2022118421,
title = {Waveguide quality inspection in quantum cascade lasers: A capsule neural network approach},
journal = {Expert Systems with Applications},
volume = {210},
pages = {118421},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118421},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422015238},
author = {Abd Al Rahman M. {Abu Ebayyeh} and Alireza Mousavi and Sebelan Danishvar and Stéphane Blaser and Tobias Gresch and Olivier Landry and Antoine Müller},
keywords = {Automatic optical inspection, Capsule networks, Convolutional neural networks, Deep learning, Defect inspection, Optoelectronic industry, Quantum cascade lasers},
abstract = {Growing demand for consumer electronic devices and telecommunications is expected to drive the quantum cascade laser (QCL) market. The increase in the production rate of QCLs increases the likelihood of production failures and anomalies. The detection of waveguide defects and dirt using automatic optical inspection (AOI) and deep learning (DL) is the main focus of this study. The images samples of QCLs were collected from a laser manufacturing plant in Europe. Due to the lack of sufficient dirt and defect samples, automatic and manual data augmentation approaches were used to increase the number of images. A combination of an improved capsule neural network (WaferCaps) and convolutional neural network (CNN) based on parallel decision fusion is used to classify the samples. The output of these classifiers were combined based on rule-based selection algorithm that chooses the performance of the best classifier according to the class. The proposed approach was compared with the performance of standalone models, different state-of-the-art DL models such as CapsNet, ResNet-50, MobileNet, DenseNet, Xception and Inception-V3 and other machine learning (ML) models such as Support Vector Machine (SVM), decision tree, k-NN and Multi-layer Perceptron (MLP). The proposed approach outperformed them all with a validation accuracy of 98.5%.}
}